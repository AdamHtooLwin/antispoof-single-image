/opt/conda/lib/python3.7/site-packages/tqdm/std.py:668: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  from pandas import Panel
Parallel mode is going ...
Model loading was finished ...
Data loading was finished ...
epoch :  1|25, iter :   36|  73,  loss : 6.6206
epoch :  1|25, iter :   72|  73,  loss : 5.3986
train_loss : 5.3531
auc : 0.7804, acc : 0.8704, precision : 0.9848, recall : 0.5645, f1_score : 0.7176
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.8474    0.9964    0.9159      1393
           1     0.9848    0.5645    0.7176       574

    accuracy                         0.8704      1967
   macro avg     0.9161    0.7804    0.8167      1967
weighted avg     0.8875    0.8704    0.8580      1967

[[1388    5]
 [ 250  324]]
-------------------------------------------------------------------------------------
test_loss : 3.3744, racc_score : 0.8704
single epoch costs 1.4898 mins
**************** Yahoo, SOTA model was updated ****************
epoch :  2|25, iter :   36|  73,  loss : 3.2128
epoch :  2|25, iter :   72|  73,  loss : 3.2664
train_loss : 3.3398
auc : 0.8878, acc : 0.8439, precision : 0.6529, recall : 0.9930, f1_score : 0.7878
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9963    0.7825    0.8766      1393
           1     0.6529    0.9930    0.7878       574

    accuracy                         0.8439      1967
   macro avg     0.8246    0.8878    0.8322      1967
weighted avg     0.8961    0.8439    0.8507      1967

[[1090  303]
 [   4  570]]
-------------------------------------------------------------------------------------
test_loss : 4.1137, racc_score : 0.8439
single epoch costs 1.3030 mins
epoch :  3|25, iter :   36|  73,  loss : 3.0722
epoch :  3|25, iter :   72|  73,  loss : 3.3432
train_loss : 3.3908
auc : 0.8807, acc : 0.8368, precision : 0.6439, recall : 0.9861, f1_score : 0.7791
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9926    0.7753    0.8706      1393
           1     0.6439    0.9861    0.7791       574

    accuracy                         0.8368      1967
   macro avg     0.8183    0.8807    0.8248      1967
weighted avg     0.8909    0.8368    0.8439      1967

[[1080  313]
 [   8  566]]
-------------------------------------------------------------------------------------
test_loss : 3.8699, racc_score : 0.8368
single epoch costs 1.2879 mins
epoch :  4|25, iter :   36|  73,  loss : 3.3645
epoch :  4|25, iter :   72|  73,  loss : 3.2645
train_loss : 3.2529
auc : 0.9711, acc : 0.9700, precision : 0.9270, recall : 0.9739, f1_score : 0.9499
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9890    0.9684    0.9786      1393
           1     0.9270    0.9739    0.9499       574

    accuracy                         0.9700      1967
   macro avg     0.9580    0.9711    0.9642      1967
weighted avg     0.9709    0.9700    0.9702      1967

[[1349   44]
 [  15  559]]
-------------------------------------------------------------------------------------
test_loss : 1.6377, racc_score : 0.9700
single epoch costs 1.2987 mins
**************** Yahoo, SOTA model was updated ****************
epoch :  5|25, iter :   36|  73,  loss : 2.9122
epoch :  5|25, iter :   72|  73,  loss : 3.1885
train_loss : 3.2114
auc : 0.9400, acc : 0.9187, precision : 0.7859, recall : 0.9913, f1_score : 0.8767
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9960    0.8887    0.9393      1393
           1     0.7859    0.9913    0.8767       574

    accuracy                         0.9187      1967
   macro avg     0.8909    0.9400    0.9080      1967
weighted avg     0.9347    0.9187    0.9210      1967

[[1238  155]
 [   5  569]]
-------------------------------------------------------------------------------------
test_loss : 3.6608, racc_score : 0.9187
single epoch costs 1.2274 mins
epoch :  6|25, iter :   36|  73,  loss : 2.8404
epoch :  6|25, iter :   72|  73,  loss : 2.7353
train_loss : 2.7536
auc : 0.9792, acc : 0.9705, precision : 0.9082, recall : 1.0000, f1_score : 0.9519
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     1.0000    0.9584    0.9787      1393
           1     0.9082    1.0000    0.9519       574

    accuracy                         0.9705      1967
   macro avg     0.9541    0.9792    0.9653      1967
weighted avg     0.9732    0.9705    0.9709      1967

[[1335   58]
 [   0  574]]
-------------------------------------------------------------------------------------
test_loss : 1.9217, racc_score : 0.9705
single epoch costs 1.3376 mins
**************** Yahoo, SOTA model was updated ****************
epoch :  7|25, iter :   36|  73,  loss : 2.2745
epoch :  7|25, iter :   72|  73,  loss : 2.0292
train_loss : 2.0712
auc : 0.9833, acc : 0.9822, precision : 0.9545, recall : 0.9861, f1_score : 0.9700
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9942    0.9806    0.9874      1393
           1     0.9545    0.9861    0.9700       574

    accuracy                         0.9822      1967
   macro avg     0.9743    0.9833    0.9787      1967
weighted avg     0.9826    0.9822    0.9823      1967

[[1366   27]
 [   8  566]]
-------------------------------------------------------------------------------------
test_loss : 1.7513, racc_score : 0.9822
single epoch costs 1.2880 mins
**************** Yahoo, SOTA model was updated ****************
epoch :  8|25, iter :   36|  73,  loss : 2.3014
epoch :  8|25, iter :   72|  73,  loss : 2.1180
train_loss : 2.1560
auc : 0.9949, acc : 0.9949, precision : 0.9879, recall : 0.9948, f1_score : 0.9913
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9978    0.9950    0.9964      1393
           1     0.9879    0.9948    0.9913       574

    accuracy                         0.9949      1967
   macro avg     0.9929    0.9949    0.9939      1967
weighted avg     0.9949    0.9949    0.9949      1967

[[1386    7]
 [   3  571]]
-------------------------------------------------------------------------------------
test_loss : 0.7031, racc_score : 0.9949
single epoch costs 1.2845 mins
**************** Yahoo, SOTA model was updated ****************
epoch :  9|25, iter :   36|  73,  loss : 1.4194
epoch :  9|25, iter :   72|  73,  loss : 1.6151
train_loss : 1.5981
auc : 0.9966, acc : 0.9959, precision : 0.9879, recall : 0.9983, f1_score : 0.9931
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9993    0.9950    0.9971      1393
           1     0.9879    0.9983    0.9931       574

    accuracy                         0.9959      1967
   macro avg     0.9936    0.9966    0.9951      1967
weighted avg     0.9960    0.9959    0.9959      1967

[[1386    7]
 [   1  573]]
-------------------------------------------------------------------------------------
test_loss : 0.7176, racc_score : 0.9959
single epoch costs 1.2546 mins
**************** Yahoo, SOTA model was updated ****************
epoch : 10|25, iter :   36|  73,  loss : 1.7040
epoch : 10|25, iter :   72|  73,  loss : 1.4364
train_loss : 1.4259
auc : 0.9914, acc : 0.9878, precision : 0.9599, recall : 1.0000, f1_score : 0.9795
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     1.0000    0.9828    0.9913      1393
           1     0.9599    1.0000    0.9795       574

    accuracy                         0.9878      1967
   macro avg     0.9799    0.9914    0.9854      1967
weighted avg     0.9883    0.9878    0.9879      1967

[[1369   24]
 [   0  574]]
-------------------------------------------------------------------------------------
test_loss : 1.1414, racc_score : 0.9878
single epoch costs 1.2771 mins
epoch : 11|25, iter :   36|  73,  loss : 1.0974
epoch : 11|25, iter :   72|  73,  loss : 0.9648
train_loss : 0.9650
auc : 0.9978, acc : 0.9969, precision : 0.9897, recall : 1.0000, f1_score : 0.9948
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     1.0000    0.9957    0.9978      1393
           1     0.9897    1.0000    0.9948       574

    accuracy                         0.9969      1967
   macro avg     0.9948    0.9978    0.9963      1967
weighted avg     0.9970    0.9969    0.9970      1967

[[1387    6]
 [   0  574]]
-------------------------------------------------------------------------------------
test_loss : 0.5103, racc_score : 0.9969
single epoch costs 1.3291 mins
**************** Yahoo, SOTA model was updated ****************
epoch : 12|25, iter :   36|  73,  loss : 1.1920
epoch : 12|25, iter :   72|  73,  loss : 1.1419
train_loss : 1.1422
auc : 0.9905, acc : 0.9873, precision : 0.9598, recall : 0.9983, f1_score : 0.9787
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9993    0.9828    0.9910      1393
           1     0.9598    0.9983    0.9787       574

    accuracy                         0.9873      1967
   macro avg     0.9795    0.9905    0.9848      1967
weighted avg     0.9878    0.9873    0.9874      1967

[[1369   24]
 [   1  573]]
-------------------------------------------------------------------------------------
test_loss : 1.4396, racc_score : 0.9873
single epoch costs 1.2739 mins
epoch : 13|25, iter :   36|  73,  loss : 1.0965
epoch : 13|25, iter :   72|  73,  loss : 1.1162
train_loss : 1.1069
auc : 0.9989, acc : 0.9985, precision : 0.9948, recall : 1.0000, f1_score : 0.9974
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     1.0000    0.9978    0.9989      1393
           1     0.9948    1.0000    0.9974       574

    accuracy                         0.9985      1967
   macro avg     0.9974    0.9989    0.9982      1967
weighted avg     0.9985    0.9985    0.9985      1967

[[1390    3]
 [   0  574]]
-------------------------------------------------------------------------------------
test_loss : 0.3012, racc_score : 0.9985
single epoch costs 1.2885 mins
**************** Yahoo, SOTA model was updated ****************
epoch : 14|25, iter :   36|  73,  loss : 0.5902
epoch : 14|25, iter :   72|  73,  loss : 0.5717
train_loss : 0.6165
